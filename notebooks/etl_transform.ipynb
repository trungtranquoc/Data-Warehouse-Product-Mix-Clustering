{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "046a6b8d",
   "metadata": {},
   "source": [
    "# Assignment - ETL transform to DWH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b70b3c",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9572768",
   "metadata": {},
   "source": [
    "### 1.1 Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74ed798d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy.schema import CreateSchema\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import pandas as pd\n",
    "from urllib.parse import quote_plus\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df142c68",
   "metadata": {},
   "source": [
    "### 1.2 Database connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9688ca",
   "metadata": {},
   "source": [
    "#### 1.2.a MSSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a8710d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection failed: (pyodbc.OperationalError) ('HYT00', '[HYT00] [Microsoft][ODBC Driver 18 for SQL Server]Login timeout expired (0) (SQLDriverConnect)')\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Engine(mssql+pyodbc:///?odbc_connect=DRIVER%3D%7BODBC+Driver+18+for+SQL+Server%7D%3BSERVER%3D127.0.0.1%2C1433%3BDATABASE%3Dmaster%3BUID%3Dsa%3BPWD%3Dtrung_password123%3BTrustServerCertificate%3Dyes%3B)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_name = os.getenv('MSSQL_SERVER_NAME')\n",
    "database_name = os.getenv('MSSQL_DATABASE_NAME')\n",
    "username = os.getenv('MSSQL_USER_NAME')\n",
    "password = os.getenv('MSSQL_PASSWORD')\n",
    "driver_name = os.getenv('MSSQL_DRIVER_NAME')\n",
    "\n",
    "# Add your port number here (1433 is default)\n",
    "port_number = int(os.getenv('MSSQL_PORT_NUMBER'))\n",
    "\n",
    "raw_connection_string = (\n",
    "    f'DRIVER={{{driver_name}}};'\n",
    "    f'SERVER={server_name},{port_number};' # Note the 'host,port' format\n",
    "    f'DATABASE={database_name};'\n",
    "    f'UID={username};'\n",
    "    f'PWD={password};'\n",
    "    # **CRITICAL: This is the trust connection setting you need**\n",
    "    f'TrustServerCertificate=yes;' \n",
    ")\n",
    "\n",
    "quoted_connection_string = quote_plus(raw_connection_string)\n",
    "\n",
    "connection_url = f\"mssql+pyodbc:///?odbc_connect={quoted_connection_string}\"\n",
    "\n",
    "mssql_engine = create_engine(connection_url)\n",
    "try:\n",
    "    with mssql_engine.connect() as conn:\n",
    "        # optional: issue a lightweight query\n",
    "        conn.execute(text(\"SELECT 1\"))\n",
    "    print(\"Connection successful\")\n",
    "except SQLAlchemyError as e:\n",
    "    print(\"Connection failed:\", e)\n",
    "    # handle/log error accordingly\n",
    "\n",
    "mssql_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e54118",
   "metadata": {},
   "source": [
    "#### 1.2.b PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "004451ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(postgresql+psycopg2://postgres:***@localhost:5432/postgres)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_name = os.getenv('POSTGRESQL_SERVER_NAME')\n",
    "database_name = os.getenv('POSTGRESQL_DATABASE_NAME')\n",
    "username = os.getenv('POSTGRESQL_USER_NAME')\n",
    "password = os.getenv('POSTGRESQL_PASSWORD')\n",
    "driver_name = os.getenv('POSTGRESQL_DRIVER_NAME')\n",
    "\n",
    "port_number = int(os.getenv('POSTGRESQL_PORT_NUMBER'))\n",
    "\n",
    "# Modified connection_url with the port:\n",
    "connection_url = f\"postgresql+psycopg2://{username}:{password}@{server_name}:{port_number}/{database_name}\"\n",
    "\n",
    "postgre_engine = create_engine(connection_url)\n",
    "postgre_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0af3a7d",
   "metadata": {},
   "source": [
    "## 2. Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca3bb38",
   "metadata": {},
   "source": [
    "Extract and process tables:\n",
    "\n",
    "- Table `Product`: only keep those sellable items\n",
    "\n",
    "- Tables `ProductCostHistory`, `ProductListPriceHistory`: merge them into a single table\n",
    "\n",
    "- Tables `SalesOrderDetail`, `SalesOrderHeader`: retrieve `OrderDate` from `SalesOrderHeader` and merge to `SalesOrderDetail`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4935855c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 504 entries, 0 to 503\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   ProductID             504 non-null    int64         \n",
      " 1   Name                  504 non-null    object        \n",
      " 2   ProductSubcategoryID  295 non-null    float64       \n",
      " 3   FinishedGoodsFlag     504 non-null    bool          \n",
      " 4   SellStartDate         504 non-null    datetime64[ns]\n",
      " 5   SellEndDate           98 non-null     datetime64[ns]\n",
      "dtypes: bool(1), datetime64[ns](2), float64(1), int64(1), object(1)\n",
      "memory usage: 20.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load table product\n",
    "input_product_df = pd.read_sql(\"\"\"\n",
    "        SELECT ProductID, Name, ProductSubcategoryID, FinishedGoodsFlag, SellStartDate, SellEndDate\n",
    "        FROM CompanyX.Production.Product\n",
    "    \"\"\".strip(), mssql_engine)\n",
    "\n",
    "input_product_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "428866c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37 entries, 0 to 36\n",
      "Data columns (total 3 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   ProductSubcategoryID  37 non-null     int64 \n",
      " 1   Name                  37 non-null     object\n",
      " 2   ProductCategoryID     37 non-null     int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1020.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# Load table ProductSubCategory\n",
    "input_psc_df = pd.read_sql(\"\"\"\n",
    "        SELECT ProductSubcategoryID, Name, ProductCategoryID\n",
    "        FROM CompanyX.Production.ProductSubcategory\n",
    "    \"\"\".strip(), mssql_engine)\n",
    "\n",
    "input_psc_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc8b767b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 2 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   ProductCategoryID  4 non-null      int64 \n",
      " 1   Name               4 non-null      object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 196.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# Load table ProductCategory\n",
    "input_pc_df = pd.read_sql(\"\"\"\n",
    "        SELECT ProductCategoryID, Name\n",
    "        FROM CompanyX.Production.ProductCategory\n",
    "    \"\"\".strip(), mssql_engine)\n",
    "\n",
    "input_pc_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b98e3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of products having pricecost history: 293\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 395 entries, 0 to 394\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   ProductID     395 non-null    int64         \n",
      " 1   StartDate     395 non-null    datetime64[ns]\n",
      " 2   EndDate       200 non-null    datetime64[ns]\n",
      " 3   StandardCost  395 non-null    float64       \n",
      " 4   ListPrice     395 non-null    float64       \n",
      "dtypes: datetime64[ns](2), float64(2), int64(1)\n",
      "memory usage: 15.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Load table ProductCostHistory, ProductListPriceHistory\n",
    "input_pch_df = pd.read_sql(\"\"\"\n",
    "        SELECT ProductID, StartDate, EndDate, StandardCost\n",
    "        FROM CompanyX.Production.ProductCostHistory\n",
    "    \"\"\".strip(), mssql_engine)\n",
    "\n",
    "input_plph_df = pd.read_sql(\"\"\"\n",
    "        SELECT ProductID, StartDate, EndDate, ListPrice\n",
    "        FROM CompanyX.Production.ProductListPriceHistory\n",
    "    \"\"\".strip(), mssql_engine)\n",
    "\n",
    "pricecost_df = pd.merge(input_pch_df, input_plph_df, on=['ProductID', 'StartDate', 'EndDate'], how='inner')\n",
    "history_available_products = pricecost_df['ProductID'].unique().tolist()\n",
    "\n",
    "print(f\"Number of products having pricecost history: {len(history_available_products)}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "pricecost_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99987072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 121317 entries, 0 to 121316\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   ProductID     121317 non-null  int64         \n",
      " 1   OrderQty      121302 non-null  float64       \n",
      " 2   LineTotal     121317 non-null  float64       \n",
      " 3   SalesOrderID  121317 non-null  int64         \n",
      " 4   OrderDate     121317 non-null  datetime64[ns]\n",
      " 5   CustomerID    121317 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(3)\n",
      "memory usage: 5.6 MB\n"
     ]
    }
   ],
   "source": [
    "# Load table SalesOrderDetail\n",
    "input_sod_df = pd.read_sql(\"\"\"\n",
    "        SELECT ProductID, OrderQty, LineTotal, SalesOrderID\n",
    "        FROM CompanyX.Sales.SalesOrderDetail\n",
    "    \"\"\".strip(), mssql_engine)\n",
    "\n",
    "# Load data SalesOrderHeader\n",
    "input_soh_df = pd.read_sql(\"\"\"\n",
    "        SELECT SalesOrderID, OrderDate, CustomerID\n",
    "        FROM CompanyX.Sales.SalesOrderHeader\n",
    "    \"\"\".strip(), mssql_engine)\n",
    "\n",
    "input_sod_df = pd.merge(input_sod_df, input_soh_df[['SalesOrderID', 'OrderDate', 'CustomerID']], on='SalesOrderID', how='left')\n",
    "\n",
    "input_sod_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "398f29d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19820 entries, 0 to 19819\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   CustomerID   19820 non-null  int64  \n",
      " 1   PersonID     19119 non-null  float64\n",
      " 2   StoreID      1336 non-null   float64\n",
      " 3   TerritoryID  19820 non-null  int64  \n",
      "dtypes: float64(2), int64(2)\n",
      "memory usage: 619.5 KB\n"
     ]
    }
   ],
   "source": [
    "# Load table Customer\n",
    "input_customer_df = pd.read_sql(\"\"\"\n",
    "        SELECT CustomerID, PersonID, StoreID, TerritoryID\n",
    "        FROM CompanyX.Sales.Customer\n",
    "    \"\"\".strip(), mssql_engine)\n",
    "\n",
    "input_customer_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d16f69ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   TerritoryID  10 non-null     int64 \n",
      " 1   Name         10 non-null     object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 292.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# Load table Territory\n",
    "input_territory_df = pd.read_sql(\"\"\"\n",
    "        SELECT TerritoryID, Name\n",
    "        FROM CompanyX.Sales.SalesTerritory\n",
    "    \"\"\".strip(), mssql_engine)\n",
    "\n",
    "input_territory_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acc6ea9",
   "metadata": {},
   "source": [
    "## 3. Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aedfab",
   "metadata": {},
   "source": [
    "### 3.1 Product dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3664ce96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of products: 504\n",
      "Number of salable products: 293\n",
      "Number of product categories: 4\n",
      "Number of product subcategories: 37\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 293 entries, 0 to 292\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   ProductID             293 non-null    int64         \n",
      " 1   Name                  293 non-null    object        \n",
      " 2   ProductSubcategoryID  293 non-null    float64       \n",
      " 3   SellStartDate         293 non-null    datetime64[ns]\n",
      " 4   SellEndDate           98 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(1), int64(1), object(1)\n",
      "memory usage: 11.6+ KB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of products: {len(input_product_df)}\")\n",
    "\n",
    "# drop non-salable products\n",
    "dim_product_df = input_product_df[input_product_df['FinishedGoodsFlag'] == 1].reset_index(drop=True).drop(columns=['FinishedGoodsFlag']).copy()\n",
    "dim_product_df = dim_product_df[dim_product_df['ProductID'].isin(history_available_products)].reset_index(drop=True)\n",
    "\n",
    "# keep tracks of salable products\n",
    "salable_products = list(dim_product_df['ProductID'].unique())\n",
    "print(f\"Number of salable products: {len(salable_products)}\")\n",
    "\n",
    "# Keep subcategory and category\n",
    "dim_category_df = input_pc_df.copy()\n",
    "dim_subcategory_df = input_psc_df.copy()\n",
    "\n",
    "print(f\"Number of product categories: {len(dim_category_df)}\")\n",
    "print(f\"Number of product subcategories: {len(dim_subcategory_df)}\")\n",
    "\n",
    "print(f\"-\" * 50)\n",
    "\n",
    "# check missing status\n",
    "dim_product_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc34fee",
   "metadata": {},
   "source": [
    "### 3.2 Price Cost History mini-dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "441975f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 395 entries, 0 to 394\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   HistoryKey    395 non-null    int64         \n",
      " 1   ProductID     395 non-null    int64         \n",
      " 2   StartDate     395 non-null    datetime64[ns]\n",
      " 3   EndDate       200 non-null    datetime64[ns]\n",
      " 4   StandardCost  395 non-null    float64       \n",
      " 5   ListPrice     395 non-null    float64       \n",
      "dtypes: datetime64[ns](2), float64(2), int64(2)\n",
      "memory usage: 18.6 KB\n"
     ]
    }
   ],
   "source": [
    "# create a surrogate for pricecost history table\n",
    "dim_pricecost_df = pricecost_df[pricecost_df['ProductID'].isin(salable_products)].reset_index(drop=True).copy()\n",
    "dim_pricecost_df.insert(0, 'HistoryKey', range(1, 1 + len(dim_pricecost_df)))\n",
    "\n",
    "dim_pricecost_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67996af",
   "metadata": {},
   "source": [
    "### 3.3 Customer Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a395710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19820 entries, 0 to 19819\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   CustomerID   19820 non-null  int64  \n",
      " 1   PersonID     19119 non-null  float64\n",
      " 2   StoreID      1336 non-null   float64\n",
      " 3   TerritoryID  19820 non-null  int64  \n",
      "dtypes: float64(2), int64(2)\n",
      "memory usage: 619.5 KB\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   TerritoryID  10 non-null     int64 \n",
      " 1   Name         10 non-null     object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 292.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "dim_customer_df = input_customer_df.copy()\n",
    "dim_territory_df = input_territory_df.copy()\n",
    "\n",
    "dim_customer_df.info()\n",
    "print(f\"-\" * 50)\n",
    "dim_territory_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc992699",
   "metadata": {},
   "source": [
    "### 3.4 Time dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56e83fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1124 entries, 0 to 1123\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   date     1124 non-null   datetime64[ns]\n",
      " 1   month    1124 non-null   int32         \n",
      " 2   quarter  1124 non-null   int32         \n",
      " 3   year     1124 non-null   int32         \n",
      "dtypes: datetime64[ns](1), int32(3)\n",
      "memory usage: 22.1 KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "unique_time_lists = pd.to_datetime(input_sod_df['OrderDate'].unique())\n",
    "datetime_arr = pd.DatetimeIndex(unique_time_lists).to_numpy()\n",
    "\n",
    "sorted_indices = np.argsort(datetime_arr)\n",
    "unique_time_lists = unique_time_lists[sorted_indices]\n",
    "\n",
    "dim_time_df = pd.DataFrame({\n",
    "    'date': unique_time_lists,\n",
    "    'month': unique_time_lists.month,\n",
    "    'quarter': unique_time_lists.quarter,\n",
    "    'year': unique_time_lists.year,\n",
    "})\n",
    "\n",
    "dim_time_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a988a23",
   "metadata": {},
   "source": [
    "### 3.4 Fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04c95202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 121246 entries, 0 to 121245\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   ProductID     121246 non-null  int64         \n",
      " 1   OrderQty      121246 non-null  float64       \n",
      " 2   LineTotal     121246 non-null  float64       \n",
      " 3   SalesOrderID  121246 non-null  int64         \n",
      " 4   OrderDate     121246 non-null  datetime64[ns]\n",
      " 5   CustomerID    121246 non-null  int64         \n",
      " 6   HistoryKey    121246 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(4)\n",
      "memory usage: 6.5 MB\n"
     ]
    }
   ],
   "source": [
    "fact_sales_df = input_sod_df.copy()\n",
    "dim_pricecost_df[\"EndDate\"] = dim_pricecost_df[\"EndDate\"].fillna(pd.Timestamp.max)\n",
    "\n",
    "def assign_interval(fact_df: pd.DataFrame, dim_df: pd.DataFrame, date_col=\"OrderDate\"):\n",
    "    dim = dim_df.sort_values([\"StartDate\", \"ProductID\"])\n",
    "    fact = fact_df.sort_values([date_col, \"ProductID\"])\n",
    "\n",
    "    merged = pd.merge(\n",
    "        fact,\n",
    "        dim,\n",
    "        left_on=[\"ProductID\"],\n",
    "        right_on=[\"ProductID\"],\n",
    "        how='left',\n",
    "    )\n",
    "\n",
    "    return merged[\n",
    "        (merged[date_col] >= merged[\"StartDate\"]) &\n",
    "        (merged[date_col] <= merged[\"EndDate\"])\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "fact_sales_df = assign_interval(fact_sales_df, dim_pricecost_df[[\"HistoryKey\", \"ProductID\", \"StartDate\", \"EndDate\"]], date_col=\"OrderDate\")\n",
    "fact_sales_df.drop(columns=['StartDate', 'EndDate'], inplace=True)\n",
    "fact_sales_df['OrderQty'] = fact_sales_df['OrderQty'].fillna(0)\n",
    "\n",
    "fact_sales_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeecb5c",
   "metadata": {},
   "source": [
    "## 4. Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8827c17c",
   "metadata": {},
   "source": [
    "### 4.1 Create new schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92632146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema 'dwh' created successfully (or already exists).\n"
     ]
    }
   ],
   "source": [
    "schema_name = 'dwh'\n",
    "\n",
    "with postgre_engine.connect() as connection:\n",
    "    try:\n",
    "        connection.execute(CreateSchema(schema_name, if_not_exists=True))\n",
    "        connection.commit()\n",
    "        print(f\"Schema '{schema_name}' created successfully (or already exists).\")\n",
    "    except Exception as e:\n",
    "        connection.rollback()\n",
    "        print(f\"Error creating schema '{schema_name}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090b30c3",
   "metadata": {},
   "source": [
    "### 4.2 Write data into schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d48ba9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETL process completed and data loaded into PostgreSQL data warehouse.\n"
     ]
    }
   ],
   "source": [
    "# Product Dim\n",
    "dim_product_df.to_sql('DimProduct', postgre_engine, schema=schema_name, if_exists='replace', index=False)\n",
    "dim_subcategory_df.to_sql('DimSubcategory', postgre_engine, schema=schema_name, if_exists='replace', index=False)\n",
    "dim_category_df.to_sql('DimCategory', postgre_engine, schema=schema_name, if_exists='replace', index=False)\n",
    "\n",
    "# History Dim\n",
    "dim_pricecost_df[['HistoryKey', 'StandardCost', 'ListPrice']].to_sql('DimPriceCostHistory', postgre_engine, schema=schema_name, if_exists='replace', index=False)\n",
    "\n",
    "# Customer Dim\n",
    "dim_customer_df.to_sql('DimCustomer', postgre_engine, schema=schema_name, if_exists='replace', index=False)\n",
    "dim_territory_df.to_sql('DimTerritory', postgre_engine, schema=schema_name, if_exists='replace', index=False)\n",
    "\n",
    "# Time Dim\n",
    "dim_time_df.to_sql('DimDate', postgre_engine, schema=schema_name, if_exists='replace', index=False)\n",
    "\n",
    "# Fact Table\n",
    "fact_sales_df.to_sql('FactProductSales', postgre_engine, schema=schema_name, if_exists='replace', index=False)\n",
    "\n",
    "print(\"ETL process completed and data loaded into PostgreSQL data warehouse.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
