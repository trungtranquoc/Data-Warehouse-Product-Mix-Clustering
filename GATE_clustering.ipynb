{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16816cb1",
   "metadata": {},
   "source": [
    "# Graph Neural Network for clustering\n",
    "\n",
    "In this notebook, we construct Graph Attention Autoencoder (GATE) architecture from paper *\"Graph Attention Auto-Encoders\"* to learn the low-dimension embeddings of products from its' time-series features that have been learned by LSTM Autoencoder.\n",
    "- Graph input: graph built to connect products within subcategories group, we aim to capture the contrastive among those subcategories group.\n",
    "- Clustering: apply KMeans on low-dimension embeddings of products, learned by GATE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e5e1e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (2.7.1)\n",
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m873.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (3.10.3)\n",
      "Requirement already satisfied: filelock in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: aiohttp in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from torch_geometric) (3.12.13)\n",
      "Requirement already satisfied: numpy in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from torch_geometric) (2.3.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from torch_geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from torch_geometric) (3.2.3)\n",
      "Requirement already satisfied: requests in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from torch_geometric) (2.32.4)\n",
      "Requirement already satisfied: tqdm in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from torch_geometric) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from torch_geometric) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from aiohttp->torch_geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from aiohttp->torch_geometric) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from aiohttp->torch_geometric) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from aiohttp->torch_geometric) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from aiohttp->torch_geometric) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from aiohttp->torch_geometric) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from aiohttp->torch_geometric) (1.20.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from requests->torch_geometric) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from requests->torch_geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from requests->torch_geometric) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/trantrunghcmut/.pyenv/versions/3.11.13/lib/python3.11/site-packages (from requests->torch_geometric) (2025.6.15)\n",
      "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.7.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torch_geometric matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea26689a",
   "metadata": {},
   "source": [
    "### Load embeddings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c785935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ProductID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>0.016641</td>\n",
       "      <td>-0.796348</td>\n",
       "      <td>-0.424462</td>\n",
       "      <td>1.146192</td>\n",
       "      <td>-0.341899</td>\n",
       "      <td>-2.166074</td>\n",
       "      <td>0.134770</td>\n",
       "      <td>-0.430464</td>\n",
       "      <td>0.148232</td>\n",
       "      <td>0.014255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099478</td>\n",
       "      <td>-0.618858</td>\n",
       "      <td>-0.049329</td>\n",
       "      <td>0.050487</td>\n",
       "      <td>0.334427</td>\n",
       "      <td>-0.214072</td>\n",
       "      <td>0.070194</td>\n",
       "      <td>1.170232</td>\n",
       "      <td>0.146769</td>\n",
       "      <td>2.693363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>0.051593</td>\n",
       "      <td>-0.902200</td>\n",
       "      <td>-0.425973</td>\n",
       "      <td>1.068647</td>\n",
       "      <td>-0.327741</td>\n",
       "      <td>-2.268141</td>\n",
       "      <td>0.422152</td>\n",
       "      <td>-0.364571</td>\n",
       "      <td>0.046346</td>\n",
       "      <td>0.819576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178698</td>\n",
       "      <td>-0.603789</td>\n",
       "      <td>-0.016058</td>\n",
       "      <td>0.074833</td>\n",
       "      <td>0.315111</td>\n",
       "      <td>-0.254949</td>\n",
       "      <td>0.111341</td>\n",
       "      <td>1.161034</td>\n",
       "      <td>0.196277</td>\n",
       "      <td>2.804454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0.011487</td>\n",
       "      <td>-0.725108</td>\n",
       "      <td>-0.424914</td>\n",
       "      <td>1.100861</td>\n",
       "      <td>-0.250419</td>\n",
       "      <td>-2.179343</td>\n",
       "      <td>0.273201</td>\n",
       "      <td>-0.423647</td>\n",
       "      <td>0.102147</td>\n",
       "      <td>0.172975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096076</td>\n",
       "      <td>-0.581600</td>\n",
       "      <td>-0.055827</td>\n",
       "      <td>0.045036</td>\n",
       "      <td>0.243844</td>\n",
       "      <td>-0.218252</td>\n",
       "      <td>0.064921</td>\n",
       "      <td>1.213822</td>\n",
       "      <td>0.151609</td>\n",
       "      <td>2.702350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>0.082089</td>\n",
       "      <td>-0.705805</td>\n",
       "      <td>-0.160028</td>\n",
       "      <td>0.621171</td>\n",
       "      <td>0.149819</td>\n",
       "      <td>-2.350944</td>\n",
       "      <td>1.628704</td>\n",
       "      <td>-0.105593</td>\n",
       "      <td>0.171692</td>\n",
       "      <td>1.460141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279286</td>\n",
       "      <td>-0.620832</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.043463</td>\n",
       "      <td>-0.220858</td>\n",
       "      <td>-0.320969</td>\n",
       "      <td>0.189366</td>\n",
       "      <td>1.274447</td>\n",
       "      <td>0.312974</td>\n",
       "      <td>2.582912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>0.680826</td>\n",
       "      <td>1.924417</td>\n",
       "      <td>-0.556740</td>\n",
       "      <td>0.518928</td>\n",
       "      <td>0.391095</td>\n",
       "      <td>-1.682862</td>\n",
       "      <td>-0.400020</td>\n",
       "      <td>-1.416731</td>\n",
       "      <td>-0.491055</td>\n",
       "      <td>-0.593432</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037703</td>\n",
       "      <td>0.073459</td>\n",
       "      <td>0.301301</td>\n",
       "      <td>0.201766</td>\n",
       "      <td>1.128518</td>\n",
       "      <td>-2.446335</td>\n",
       "      <td>0.414793</td>\n",
       "      <td>-0.942614</td>\n",
       "      <td>-1.503768</td>\n",
       "      <td>-1.502835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3         4         5  \\\n",
       "ProductID                                                               \n",
       "707        0.016641 -0.796348 -0.424462  1.146192 -0.341899 -2.166074   \n",
       "708        0.051593 -0.902200 -0.425973  1.068647 -0.327741 -2.268141   \n",
       "711        0.011487 -0.725108 -0.424914  1.100861 -0.250419 -2.179343   \n",
       "712        0.082089 -0.705805 -0.160028  0.621171  0.149819 -2.350944   \n",
       "713        0.680826  1.924417 -0.556740  0.518928  0.391095 -1.682862   \n",
       "\n",
       "                  6         7         8         9  ...        38        39  \\\n",
       "ProductID                                          ...                       \n",
       "707        0.134770 -0.430464  0.148232  0.014255  ...  0.099478 -0.618858   \n",
       "708        0.422152 -0.364571  0.046346  0.819576  ...  0.178698 -0.603789   \n",
       "711        0.273201 -0.423647  0.102147  0.172975  ...  0.096076 -0.581600   \n",
       "712        1.628704 -0.105593  0.171692  1.460141  ...  0.279286 -0.620832   \n",
       "713       -0.400020 -1.416731 -0.491055 -0.593432  ... -0.037703  0.073459   \n",
       "\n",
       "                 40        41        42        43        44        45  \\\n",
       "ProductID                                                               \n",
       "707       -0.049329  0.050487  0.334427 -0.214072  0.070194  1.170232   \n",
       "708       -0.016058  0.074833  0.315111 -0.254949  0.111341  1.161034   \n",
       "711       -0.055827  0.045036  0.243844 -0.218252  0.064921  1.213822   \n",
       "712        0.003077  0.043463 -0.220858 -0.320969  0.189366  1.274447   \n",
       "713        0.301301  0.201766  1.128518 -2.446335  0.414793 -0.942614   \n",
       "\n",
       "                 46        47  \n",
       "ProductID                      \n",
       "707        0.146769  2.693363  \n",
       "708        0.196277  2.804454  \n",
       "711        0.151609  2.702350  \n",
       "712        0.312974  2.582912  \n",
       "713       -1.503768 -1.502835  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "embeddings_df = pd.read_csv('data/product_lstm_embeddings.csv')\n",
    "embeddings_df.set_index('ProductID', inplace=True)\n",
    "\n",
    "active_products = embeddings_df.index\n",
    "\n",
    "embeddings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7362ba",
   "metadata": {},
   "source": [
    "### 1. Construct product-product graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b67137bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trantrunghcmut/Documents/hcmut/semester 251/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency matrix shape: (166, 166) - Number of connections: 2050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,  ..., 165, 165, 165],\n",
       "        [  0,   1,   2,  ..., 163, 164, 165]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.utils import dense_to_sparse\n",
    "\n",
    "dimProduct_df = pd.read_csv('data/dimProduct.csv')\n",
    "dimProduct_df = dimProduct_df[dimProduct_df['ProductID'].isin(active_products)]\n",
    "\n",
    "# Create adjacency matrix for products\n",
    "# Two products are connected if they belong to the same subcategory\n",
    "\n",
    "adjacency_matrix = pd.DataFrame(0, index=dimProduct_df['ProductID'], columns=dimProduct_df['ProductID'])\n",
    "\n",
    "for subcategory, group in dimProduct_df.groupby('ProductSubcategoryID'):\n",
    "    adjacency_matrix.loc[group['ProductID'], group['ProductID']] = 1\n",
    "\n",
    "print(f\"Adjacency matrix shape: {adjacency_matrix.shape} - Number of connections: {adjacency_matrix.values.sum()}\")\n",
    "\n",
    "# Convert to sparse matrix\n",
    "adjacency_matrix = torch.tensor(adjacency_matrix.values, dtype=torch.float32)\n",
    "edge_index, edge_weight = dense_to_sparse(adjacency_matrix)\n",
    "\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9a1789",
   "metadata": {},
   "source": [
    "## 2. Build GATE architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be18c8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class GATEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Attention Encoder (Simplified 1-Layer Version).\n",
    "    Directly maps input features to latent space using attention.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, hidden_channels: int, out_channels: int, heads=2, dropout=0.2):\n",
    "        super(GATEncoder, self).__init__()\n",
    "\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, concat=True, dropout=dropout)\n",
    "        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1, concat=False, dropout=dropout)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x: [num_nodes, in_channels]\n",
    "        x = self.dropout(x)\n",
    "        x = nn.functional.elu(self.conv1(x, edge_index))\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class FeatureDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Reconstructs the original node features (RNN embeddings) from the latent Z.\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_channels: int, hidden_channels: int, out_channels: int):\n",
    "        super(FeatureDecoder, self).__init__()\n",
    "        # Simple MLP decoder\n",
    "        self.lin1 = nn.Linear(latent_channels, hidden_channels)\n",
    "        self.lin2 = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = F.relu(self.lin1(z))\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "\n",
    "class GATEModel(nn.Module):\n",
    "    \"\"\"\n",
    "    End-to-End Graph Attention Autoencoder.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, hidden_channels: int, latent_channels: int):\n",
    "        super(GATEModel, self).__init__()\n",
    "        # Removed hidden_channels argument as we only have 1 layer\n",
    "        self.encoder = GATEncoder(in_channels, hidden_channels, latent_channels)\n",
    "        self.feature_decoder = FeatureDecoder(latent_channels, hidden_channels, in_channels)\n",
    "\n",
    "    def forward(self, x: torch.tensor, edge_index: torch.tensor):\n",
    "        z = self.encoder(x, edge_index)\n",
    "        return z\n",
    "\n",
    "    def recon_loss(self, z: torch.tensor, x: torch.tensor, edge_index: torch.tensor, lambda_feat=1, lambda_struct=0.1):\n",
    "        \"\"\"\n",
    "        Dual Reconstruction Loss.\n",
    "        \"\"\"\n",
    "        # 1. Feature Reconstruction Loss - Sum Squared Error\n",
    "        x_hat = self.feature_decoder(z)\n",
    "        loss_feat = F.mse_loss(x_hat, x)\n",
    "\n",
    "        # 2. Structure Reconstruction Loss - Only backprop through connected edges, not unconnected ones\n",
    "        adj_hat = torch.sigmoid(torch.matmul(z, z.t()))\n",
    "        loss_struct = adj_hat[edge_index[0], edge_index[1]].mean()\n",
    "\n",
    "        return (lambda_feat * loss_feat) + (lambda_struct * loss_struct), loss_feat.item(), loss_struct.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a5b83b",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2561737e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: torch.Size([166, 48])\n",
      "Model has 6464 learnable parameters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gp/jhdxg4dj4cvg1nrkhvs6lh040000gn/T/ipykernel_89410/3152985133.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index = torch.tensor(edge_index, dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam, AdamW\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Normalize embeddings\n",
    "embeddings = embeddings_df.to_numpy()\n",
    "embeddings = StandardScaler().fit_transform(embeddings)\n",
    "embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "\n",
    "\n",
    "model = GATEModel(in_channels=embeddings.shape[1], hidden_channels=32, latent_channels=16)               # Latent channgels for embeddings, so set to 8\n",
    "optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.int64)\n",
    "\n",
    "print(f\"Model has {sum(p.numel() for p in model.parameters() if p.requires_grad)} learnable parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc934160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 1.1422063112258911, Feature Loss = 1.0466008186340332, Structure Loss = 0.9560550451278687\n",
      "Epoch 200: Loss = 0.6432552933692932, Feature Loss = 0.5476865768432617, Structure Loss = 0.9556871652603149\n",
      "Epoch 400: Loss = 0.633344292640686, Feature Loss = 0.5392248630523682, Structure Loss = 0.9411945343017578\n",
      "Epoch 600: Loss = 0.6157191395759583, Feature Loss = 0.521350622177124, Structure Loss = 0.9436852931976318\n",
      "Epoch 800: Loss = 0.6156054139137268, Feature Loss = 0.5243307948112488, Structure Loss = 0.9127463698387146\n",
      "Epoch 1000: Loss = 0.6031948328018188, Feature Loss = 0.5116922855377197, Structure Loss = 0.915025532245636\n",
      "Epoch 1200: Loss = 0.6150552034378052, Feature Loss = 0.5226377248764038, Structure Loss = 0.9241746664047241\n",
      "Epoch 1400: Loss = 0.6171069145202637, Feature Loss = 0.5260453820228577, Structure Loss = 0.9106153845787048\n",
      "Epoch 1600: Loss = 0.6169811487197876, Feature Loss = 0.5235044360160828, Structure Loss = 0.9347671866416931\n",
      "Epoch 1800: Loss = 0.5874732136726379, Feature Loss = 0.4897840917110443, Structure Loss = 0.9768911004066467\n",
      "Epoch 2000: Loss = 0.5812797546386719, Feature Loss = 0.4900861084461212, Structure Loss = 0.9119365811347961\n",
      "Epoch 2200: Loss = 0.5401240587234497, Feature Loss = 0.4481184482574463, Structure Loss = 0.9200560450553894\n",
      "Epoch 2400: Loss = 0.519508957862854, Feature Loss = 0.4288979768753052, Structure Loss = 0.9061095714569092\n",
      "Epoch 2600: Loss = 0.5403565168380737, Feature Loss = 0.45002132654190063, Structure Loss = 0.9033518433570862\n",
      "Epoch 2800: Loss = 0.5171506404876709, Feature Loss = 0.42691323161125183, Structure Loss = 0.9023740887641907\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "NUM_EPOCHS = 3000\n",
    "NOTIFY_EVERY = 200\n",
    "\n",
    "model.train()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    optimizer.zero_grad()\n",
    "    z = model(embeddings, edge_index)\n",
    "    loss, loss_feat, loss_struct = model.recon_loss(z, embeddings, edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % NOTIFY_EVERY == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item()}, Feature Loss = {loss_feat}, Structure Loss = {loss_struct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e94702",
   "metadata": {},
   "source": [
    "### Get the low-dimension representation and perform embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73433885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 16)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "low_embeddings = model(embeddings, edge_index).detach().numpy()\n",
    "low_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57dc543",
   "metadata": {},
   "source": [
    "## C. Perform clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "16ac8c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 37 products\n",
      "Cluster 1: 79 products\n",
      "Cluster 2: 29 products\n",
      "Cluster 3: 21 products\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trantrunghcmut/Documents/hcmut/semester 251/.venv/lib/python3.11/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/trantrunghcmut/Documents/hcmut/semester 251/.venv/lib/python3.11/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/trantrunghcmut/Documents/hcmut/semester 251/.venv/lib/python3.11/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Cluster</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ProductSubcategoryID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25.0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Cluster                0   1   2   3\n",
       "ProductSubcategoryID                \n",
       "1.0                    3  11   6   0\n",
       "2.0                    3   0  14   1\n",
       "3.0                   16   2   4   0\n",
       "4.0                    0   5   0   0\n",
       "5.0                    0   2   0   0\n",
       "6.0                    0   2   0   0\n",
       "7.0                    0   1   0   0\n",
       "8.0                    0   2   0   0\n",
       "9.0                    0   2   0   0\n",
       "12.0                   0  13   2   0\n",
       "13.0                   0   7   0   0\n",
       "14.0                   0   9   0   0\n",
       "15.0                   0   6   0   0\n",
       "16.0                   0  13   0   0\n",
       "19.0                   1   0   0   0\n",
       "20.0                   0   3   0   0\n",
       "21.0                   6   0   0   2\n",
       "22.0                   2   0   0   1\n",
       "23.0                   1   1   0   0\n",
       "25.0                   2   0   0   1\n",
       "26.0                   1   0   0   0\n",
       "27.0                   0   0   0   1\n",
       "28.0                   0   0   0   3\n",
       "29.0                   1   0   0   0\n",
       "30.0                   0   0   0   1\n",
       "31.0                   0   0   3   0\n",
       "32.0                   1   0   0   0\n",
       "37.0                   0   0   0  11"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "NUM_CLUSTERS = 4\n",
    "\n",
    "x_compressed = PCA(n_components=15).fit_transform(embeddings_df.to_numpy())\n",
    "predictions = KMeans(n_clusters=NUM_CLUSTERS, random_state=42).fit_predict(x_compressed)\n",
    "\n",
    "for i in range(NUM_CLUSTERS):\n",
    "    cluster_size = np.sum(predictions == i)\n",
    "    print(f\"Cluster {i}: {cluster_size} products\")\n",
    "\n",
    "# Per subcategory distribution\n",
    "dimProduct_df['Cluster'] = predictions\n",
    "dimProduct_df.groupby(['ProductSubcategoryID', 'Cluster']).size().unstack(fill_value=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
