{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "046a6b8d",
   "metadata": {},
   "source": [
    "# Assignment - ETL transform to DWH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b70b3c",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9572768",
   "metadata": {},
   "source": [
    "### 1.1 Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74ed798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.schema import CreateSchema\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import pandas as pd\n",
    "from urllib.parse import quote_plus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df142c68",
   "metadata": {},
   "source": [
    "### 1.2 Database connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9688ca",
   "metadata": {},
   "source": [
    "#### 1.2.a MSSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a8710d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Engine(mssql+pyodbc:///?odbc_connect=DRIVER%3D%7BODBC+Driver+18+for+SQL+Server%7D%3BSERVER%3D127.0.0.1%2C1433%3BDATABASE%3Dmaster%3BUID%3Dsa%3BPWD%3Dtrung_password123%3BTrustServerCertificate%3Dyes%3B)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_name = '127.0.0.1'\n",
    "database_name = 'master'\n",
    "username = 'sa'\n",
    "password = 'trung_password123'\n",
    "driver_name = 'ODBC Driver 18 for SQL Server'\n",
    "# Add your port number here (1433 is default)\n",
    "port_number = 1433\n",
    "\n",
    "raw_connection_string = (\n",
    "    f'DRIVER={{{driver_name}}};'\n",
    "    f'SERVER={server_name},{port_number};' # Note the 'host,port' format\n",
    "    f'DATABASE={database_name};'\n",
    "    f'UID={username};'\n",
    "    f'PWD={password};'\n",
    "    # **CRITICAL: This is the trust connection setting you need**\n",
    "    f'TrustServerCertificate=yes;' \n",
    ")\n",
    "\n",
    "quoted_connection_string = quote_plus(raw_connection_string)\n",
    "\n",
    "connection_url = f\"mssql+pyodbc:///?odbc_connect={quoted_connection_string}\"\n",
    "\n",
    "mssql_engine = create_engine(connection_url)\n",
    "try:\n",
    "    with mssql_engine.connect() as conn:\n",
    "        # optional: issue a lightweight query\n",
    "        conn.execute(text(\"SELECT 1\"))\n",
    "    print(\"Connection successful\")\n",
    "except SQLAlchemyError as e:\n",
    "    print(\"Connection failed:\", e)\n",
    "    # handle/log error accordingly\n",
    "\n",
    "mssql_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e54118",
   "metadata": {},
   "source": [
    "#### 1.2.b PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "004451ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(postgresql+psycopg2://postgres:***@localhost:5432/postgres)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_name = 'localhost' \n",
    "database_name = 'postgres'\n",
    "username = 'postgres'\n",
    "password = 'Trungtq'\n",
    "driver_name = 'PostgreSQL JDBC Driver'\n",
    "\n",
    "# Add your port number here (1433 is default)\n",
    "port_number = 5432\n",
    "\n",
    "# Modified connection_url with the port:\n",
    "connection_url = f\"postgresql+psycopg2://{username}:{password}@{server_name}:{port_number}/{database_name}\"\n",
    "\n",
    "postgre_engine = create_engine(connection_url)\n",
    "postgre_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0af3a7d",
   "metadata": {},
   "source": [
    "## 2. Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca3bb38",
   "metadata": {},
   "source": [
    "Extract and process tables:\n",
    "\n",
    "- Table `Product`: only keep those sellable items\n",
    "\n",
    "- Tables `ProductCostHistory`, `ProductListPriceHistory`: merge them into a single table\n",
    "\n",
    "- Tables `SalesOrderDetail`, `SalesOrderHeader`: retrieve `OrderDate` from `SalesOrderHeader` and merge to `SalesOrderDetail`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4935855c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 295 entries, 0 to 294\n",
      "Data columns (total 3 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   ProductID             295 non-null    int64  \n",
      " 1   Name                  295 non-null    object \n",
      " 2   ProductSubcategoryID  295 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 7.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load table product\n",
    "input_product_df = pd.read_sql(\"\"\"\n",
    "        SELECT ProductID, Name, ProductSubcategoryID, FinishedGoodsFlag\n",
    "        FROM CompanyX.Production.Product\n",
    "    \"\"\".strip(), mssql_engine)\n",
    "\n",
    "input_product_df = input_product_df[input_product_df['FinishedGoodsFlag'] == 1].reset_index(drop=True).drop(columns=['FinishedGoodsFlag'])\n",
    "salable_products = list(input_product_df['ProductID'].unique())\n",
    "\n",
    "input_product_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "428866c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37 entries, 0 to 36\n",
      "Data columns (total 3 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   ProductSubcategoryID  37 non-null     int64 \n",
      " 1   Name                  37 non-null     object\n",
      " 2   ProductCategoryID     37 non-null     int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1020.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# Load table ProductSubCategory\n",
    "input_psc_df = pd.read_sql(\"\"\"\n",
    "        SELECT ProductSubcategoryID, Name, ProductCategoryID\n",
    "        FROM CompanyX.Production.ProductSubcategory\n",
    "    \"\"\".strip(), mssql_engine)\n",
    "\n",
    "input_psc_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc8b767b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 2 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   ProductCategoryID  4 non-null      int64 \n",
      " 1   Name               4 non-null      object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 196.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# Load table ProductCategory\n",
    "input_pc_df = pd.read_sql(\"\"\"\n",
    "        SELECT ProductCategoryID, Name\n",
    "        FROM CompanyX.Production.ProductCategory\n",
    "    \"\"\".strip(), mssql_engine)\n",
    "\n",
    "input_pc_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b98e3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 395 entries, 0 to 394\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   ProductID     395 non-null    int64         \n",
      " 1   StartDate     395 non-null    datetime64[ns]\n",
      " 2   EndDate       200 non-null    datetime64[ns]\n",
      " 3   StandardCost  395 non-null    float64       \n",
      " 4   ListPrice     395 non-null    float64       \n",
      "dtypes: datetime64[ns](2), float64(2), int64(1)\n",
      "memory usage: 15.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Load table ProductCostHistory, ProductListPriceHistory\n",
    "input_pch_df = pd.read_sql(\"\"\"\n",
    "        SELECT ProductID, StartDate, EndDate, StandardCost\n",
    "        FROM CompanyX.Production.ProductCostHistory\n",
    "    \"\"\".strip(), mssql_engine)\n",
    "\n",
    "input_plph_df = pd.read_sql(\"\"\"\n",
    "        SELECT ProductID, StartDate, EndDate, ListPrice\n",
    "        FROM CompanyX.Production.ProductListPriceHistory\n",
    "    \"\"\".strip(), mssql_engine)\n",
    "\n",
    "merge_df = pd.merge(input_pch_df, input_plph_df, on=['ProductID', 'StartDate', 'EndDate'], how='inner')\n",
    "\n",
    "# Only keep salable products\n",
    "merge_df = merge_df[merge_df['ProductID'].isin(salable_products)].reset_index(drop=True)\n",
    "\n",
    "merge_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99987072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 121317 entries, 0 to 121316\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   ProductID     121317 non-null  int64         \n",
      " 1   OrderQty      121302 non-null  float64       \n",
      " 2   LineTotal     121317 non-null  float64       \n",
      " 3   SalesOrderID  121317 non-null  int64         \n",
      " 4   OrderDate     121317 non-null  datetime64[ns]\n",
      " 5   CustomerID    121317 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(3)\n",
      "memory usage: 5.6 MB\n"
     ]
    }
   ],
   "source": [
    "# Load table SalesOrderDetail\n",
    "input_sod_df = pd.read_sql(\"\"\"\n",
    "        SELECT ProductID, OrderQty, LineTotal, SalesOrderID\n",
    "        FROM CompanyX.Sales.SalesOrderDetail\n",
    "    \"\"\".strip(), mssql_engine)\n",
    "\n",
    "# Load data SalesOrderHeader\n",
    "input_soh_df = pd.read_sql(\"\"\"\n",
    "        SELECT SalesOrderID, OrderDate, CustomerID\n",
    "        FROM CompanyX.Sales.SalesOrderHeader\n",
    "    \"\"\".strip(), mssql_engine)\n",
    "\n",
    "input_sod_df = pd.merge(input_sod_df, input_soh_df[['SalesOrderID', 'OrderDate', 'CustomerID']], on='SalesOrderID', how='left')\n",
    "\n",
    "# Only keep salable products\n",
    "input_sod_df = input_sod_df[input_sod_df['ProductID'].isin(salable_products)].reset_index(drop=True)\n",
    "\n",
    "input_sod_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acc6ea9",
   "metadata": {},
   "source": [
    "## 3. Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aedfab",
   "metadata": {},
   "source": [
    "### 3.1 `Dim` tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "610ceaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 395 entries, 0 to 394\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   ProductID     395 non-null    int64  \n",
      " 1   StandardCost  395 non-null    float64\n",
      " 2   ListPrice     395 non-null    float64\n",
      " 3   Interval      395 non-null    int64  \n",
      "dtypes: float64(2), int64(2)\n",
      "memory usage: 12.5 KB\n"
     ]
    }
   ],
   "source": [
    "# Interval dimension\n",
    "dimDate_df = merge_df[['StartDate', 'EndDate']].copy()\n",
    "dimDate_df.drop_duplicates(inplace=True)\n",
    "dimDate_df['Id'] = dimDate_df.index + 1\n",
    "\n",
    "# Product dimension\n",
    "dimProduct_df = input_product_df\n",
    "dimProductSubcategory_df = input_psc_df\n",
    "dimProductCategory_df = input_pc_df\n",
    "\n",
    "# ProductPriceCostHistory\n",
    "dimProductPriceCostHistory_df = pd.merge(merge_df, right=dimDate_df, on=['StartDate', 'EndDate'], how='inner').drop(columns=['StartDate', 'EndDate'])\n",
    "dimProductPriceCostHistory_df.rename(columns={'Id': 'Interval'}, inplace=True)\n",
    "dimProductPriceCostHistory_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e86d2cb",
   "metadata": {},
   "source": [
    "### 3.2 `Fact` tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c998d3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>OrderQty</th>\n",
       "      <th>LineTotal</th>\n",
       "      <th>SalesOrderID</th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>836</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1622.2635</td>\n",
       "      <td>48043</td>\n",
       "      <td>2012-09-30</td>\n",
       "      <td>29716</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20001</th>\n",
       "      <td>770</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1409.3820</td>\n",
       "      <td>48043</td>\n",
       "      <td>2012-09-30</td>\n",
       "      <td>29716</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20002</th>\n",
       "      <td>760</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2818.7640</td>\n",
       "      <td>48043</td>\n",
       "      <td>2012-09-30</td>\n",
       "      <td>29716</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20003</th>\n",
       "      <td>789</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13194.0900</td>\n",
       "      <td>48043</td>\n",
       "      <td>2012-09-30</td>\n",
       "      <td>29716</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20004</th>\n",
       "      <td>708</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80.7460</td>\n",
       "      <td>48043</td>\n",
       "      <td>2012-09-30</td>\n",
       "      <td>29716</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20005</th>\n",
       "      <td>715</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115.3616</td>\n",
       "      <td>48043</td>\n",
       "      <td>2012-09-30</td>\n",
       "      <td>29716</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20006</th>\n",
       "      <td>791</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5864.0400</td>\n",
       "      <td>48043</td>\n",
       "      <td>2012-09-30</td>\n",
       "      <td>29716</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20007</th>\n",
       "      <td>792</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5235.7500</td>\n",
       "      <td>48043</td>\n",
       "      <td>2012-09-30</td>\n",
       "      <td>29716</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20008</th>\n",
       "      <td>738</td>\n",
       "      <td>4.0</td>\n",
       "      <td>735.7528</td>\n",
       "      <td>48043</td>\n",
       "      <td>2012-09-30</td>\n",
       "      <td>29716</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20009</th>\n",
       "      <td>707</td>\n",
       "      <td>8.0</td>\n",
       "      <td>161.4920</td>\n",
       "      <td>48043</td>\n",
       "      <td>2012-09-30</td>\n",
       "      <td>29716</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ProductID  OrderQty   LineTotal  SalesOrderID  OrderDate  CustomerID  \\\n",
       "20000        836       5.0   1622.2635         48043 2012-09-30       29716   \n",
       "20001        770       3.0   1409.3820         48043 2012-09-30       29716   \n",
       "20002        760       6.0   2818.7640         48043 2012-09-30       29716   \n",
       "20003        789       9.0  13194.0900         48043 2012-09-30       29716   \n",
       "20004        708       4.0     80.7460         48043 2012-09-30       29716   \n",
       "20005        715       4.0    115.3616         48043 2012-09-30       29716   \n",
       "20006        791       4.0   5864.0400         48043 2012-09-30       29716   \n",
       "20007        792       4.0   5235.7500         48043 2012-09-30       29716   \n",
       "20008        738       4.0    735.7528         48043 2012-09-30       29716   \n",
       "20009        707       8.0    161.4920         48043 2012-09-30       29716   \n",
       "\n",
       "       Interval  \n",
       "20000         2  \n",
       "20001         2  \n",
       "20002         2  \n",
       "20003         2  \n",
       "20004         2  \n",
       "20005         2  \n",
       "20006         2  \n",
       "20007         2  \n",
       "20008         2  \n",
       "20009         2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def assign_interval(fact_df, dim_df, date_col=\"OrderDate\"):\n",
    "    dim = dim_df.sort_values(\"StartDate\")\n",
    "    fact = fact_df.sort_values(date_col)\n",
    "\n",
    "    merged = pd.merge_asof(\n",
    "        fact,\n",
    "        dim,\n",
    "        left_on=date_col,\n",
    "        right_on=\"StartDate\",\n",
    "        direction=\"backward\"\n",
    "    )\n",
    "\n",
    "    return merged[\n",
    "        (merged[date_col] >= merged[\"StartDate\"]) &\n",
    "        ((merged[\"EndDate\"].isna()) | (merged[date_col] <= merged[\"EndDate\"]))\n",
    "    ]\n",
    "\n",
    "\n",
    "factProductSales_df = assign_interval(input_sod_df, dimDate_df, date_col=\"OrderDate\").drop(columns=['StartDate', 'EndDate'])\n",
    "factProductSales_df.rename(columns={'Id': 'Interval'}, inplace=True)\n",
    "\n",
    "factProductSales_df.iloc[20000:20010]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecacb9ed",
   "metadata": {},
   "source": [
    "### Deal with missing value\n",
    "1. Fact table: remove those rows with NaN value, because each row is an isolated record\n",
    "2. EndDate of Dimtable: accept Null value as the interval of applying is not end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59c9ef87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 121302 entries, 0 to 121316\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   ProductID     121302 non-null  int64         \n",
      " 1   OrderQty      121302 non-null  float64       \n",
      " 2   LineTotal     121302 non-null  float64       \n",
      " 3   SalesOrderID  121302 non-null  int64         \n",
      " 4   OrderDate     121302 non-null  datetime64[ns]\n",
      " 5   CustomerID    121302 non-null  int64         \n",
      " 6   Interval      121302 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(4)\n",
      "memory usage: 7.4 MB\n"
     ]
    }
   ],
   "source": [
    "factProductSales_df.dropna(inplace=True)\n",
    "factProductSales_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeecb5c",
   "metadata": {},
   "source": [
    "## 4. Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8827c17c",
   "metadata": {},
   "source": [
    "### 4.1 Create new schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92632146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema 'dwh' created successfully (or already exists).\n"
     ]
    }
   ],
   "source": [
    "schema_name = 'dwh'\n",
    "\n",
    "with postgre_engine.connect() as connection:\n",
    "    try:\n",
    "        connection.execute(CreateSchema(schema_name, if_not_exists=True))\n",
    "        connection.commit()\n",
    "        print(f\"Schema '{schema_name}' created successfully (or already exists).\")\n",
    "    except Exception as e:\n",
    "        connection.rollback()\n",
    "        print(f\"Error creating schema '{schema_name}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090b30c3",
   "metadata": {},
   "source": [
    "### 4.2 Write data into schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d48ba9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimDate_df.to_sql('DimDate', postgre_engine, schema=schema_name, if_exists='replace', index=False)\n",
    "dimProduct_df.to_sql('DimProduct', postgre_engine, schema=schema_name, if_exists='replace', index=False)\n",
    "dimProductSubcategory_df.to_sql('DimProductSubcategory', postgre_engine, schema=schema_name, if_exists='replace', index=False)\n",
    "dimProductCategory_df.to_sql('DimProductCategory', postgre_engine, schema=schema_name, if_exists='replace', index=False)\n",
    "dimProductPriceCostHistory_df.to_sql('DimProductPriceCostHistory', postgre_engine, schema=schema_name, if_exists='replace', index=False)\n",
    "factProductSales_df.to_sql('FactProductSales', postgre_engine, schema=schema_name, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
